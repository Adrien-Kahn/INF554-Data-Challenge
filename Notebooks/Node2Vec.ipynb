{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'pecanpy'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_7408/4007894423.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      6\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0msklearn\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdecomposition\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mPCA\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      7\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 8\u001b[1;33m \u001b[1;32mfrom\u001b[0m \u001b[0mpecanpy\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mnode2vec\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      9\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mgensim\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmodels\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mWord2Vec\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     10\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mgensim\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmodels\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcallbacks\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mCallbackAny2Vec\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'pecanpy'"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import networkx as nx\n",
    "\n",
    "from sklearn.manifold import TSNE\n",
    "from sklearn.decomposition import PCA\n",
    "\n",
    "from pecanpy import node2vec\n",
    "from gensim.models import Word2Vec\n",
    "from gensim.models.callbacks import CallbackAny2Vec\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.cluster import MiniBatchKMeans\n",
    "from time import time"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "https://towardsdatascience.com/run-node2vec-faster-with-less-memory-using-pecanpy-1bdf31f136de\n",
    "\n",
    "https://towardsdatascience.com/overview-of-deep-learning-on-graph-embeddings-4305c10ad4a4\n",
    "\n",
    "https://towardsdatascience.com/node2vec-explained-graphically-749e49b7eb6b\n",
    "\n",
    "https://intel.github.io/scikit-learn-intelex/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the graph    \n",
    "G = nx.read_edgelist('../Data/coauthorship.edgelist', delimiter=' ', nodetype=int)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Walk generation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded graph\n",
      "100%|███████████████████████████████████████████████████████████████████| 2178010.0/2178010 [00:45<00:00, 48324.65it/s]\n",
      "Generated walks\n"
     ]
    }
   ],
   "source": [
    "# Loads graph and generate walks\n",
    "g = node2vec.SparseOTF(p=0.5, q=1, workers=4, verbose=True)\n",
    "g.read_edg('../Data/coauthorship_tab.edgelist', weighted=False, directed=False)\n",
    "print(\"Loaded graph\\n\")\n",
    "walks = g.simulate_walks(num_walks = 10, walk_length = 10, n_ckpts = 100, pb_len = 100)\n",
    "print(\"Generated walks\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### word2vec embedding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "class EpochLogger(CallbackAny2Vec):\n",
    "    '''Callback to report progress'''\n",
    "    def __init__(self):\n",
    "        self.epoch = 0\n",
    "        self.t0 = time()\n",
    "    def on_epoch_begin(self, model):\n",
    "        print(\"\\nEpoch #{} start\".format(self.epoch))\n",
    "        self.t0 = time()\n",
    "    def on_epoch_end(self, model):\n",
    "        print(\"Epoch #{} end\".format(self.epoch))\n",
    "        print(\"Duration of epoch: {:.2}\".format(time() - self.t0))\n",
    "        self.epoch += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Built model\n",
      "Built vocabulary\n",
      "Epoch #0 start\n",
      "Epoch #0 end\n",
      "Epoch #1 start\n",
      "Epoch #1 end\n",
      "Epoch #2 start\n",
      "Epoch #2 end\n",
      "Epoch #3 start\n",
      "Epoch #3 end\n",
      "Epoch #4 start\n",
      "Epoch #4 end\n",
      "Trained model\n"
     ]
    }
   ],
   "source": [
    "# Builds the word2vec embedding based on the previously computed walks\n",
    "\n",
    "n_dim = 100\n",
    "epoch_logger = EpochLogger()\n",
    "\n",
    "model = Word2Vec(vector_size = n_dim, window = 8, min_count = 0, sg = 1, workers = 4, hs = 1)\n",
    "print(\"Built model\")\n",
    "model.build_vocab(walks)\n",
    "print(\"\\nBuilt vocabulary\")\n",
    "model.train(walks, total_examples=model.corpus_count, epochs=5, callbacks = [epoch_logger])\n",
    "print(\"\\nTrained model\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "embedding = np.zeros((G.number_of_nodes(), n_dim))\n",
    "\n",
    "for idx, node in enumerate(G.nodes()):\n",
    "    embedding[idx, :] = model.wv[str(node)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### k-means clustering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#kmeans = KMeans(n_cluster = 5)\n",
    "kmeans = MiniBatchKMeans(n_cluster = 5)\n",
    "kmeans.fit(embedding)\n",
    "\n",
    "# Compare for different n_cluster with inertia_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluate the clustering\n",
    "\n",
    "To evaluate this clustering, we will use functions from 3.14.7 and compare the results against a random partition. Induced graph might be of interest."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
